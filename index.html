<!DOCTYPE html>
<!-- saved from url=(0019)https://danielfusaro_placeholder.com/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  

  <title>Home | Daniel Fusaro</title>
  <link rel="manifest" href="https://Bender97.github.io/site.webmanifest">
  <link rel="mask-icon" href="https://Bender97.github.io/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="stylesheet" href="data//new.css">
  <link href="data//css" rel="stylesheet">

  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <meta name="viewport" content="width=device-width">
  
  <script src="data//new.js"></script>
  <!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

  <!-- Google tag (gtag.js) -->
  <script async="" src="data//js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5BGM7X0CGL');
  </script>

  <link rel="icon" href="https://danielfusaro_placeholder.com/images/logo/nus-soc.jpg" type="image/x-icon">

  <!-- Preload the following -->
  <link rel="preload" as="image" href="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=BF-qCIIAAAAJ&citpid=1">
  <link rel="preload" as="font" href="data//css" crossorigin="anonymous">

  <script defer="" src="data//new.js"></script>
</head>


<body style="background-color: rgb(255, 255, 255);">
  <div class="wrapper">
  <header>
      <br>
      <div>
        <span class="image avatar">
            <img src="data/mypics/photo_me.jpeg" class="img1" id="avatar-image" onclick="switchImage()">
        </span>
      </div>
      <span><h1><b>Daniel Fusaro</b></h1></span>
      <br>
      <p>
        <a href="mailto:daniel.fusaro@phd.unipd.it" target="_blank"><img src="data//icons8-circled-envelope-white-color-96.png" width="16%" alt=""></a>
        &nbsp;&nbsp;
        <a href="https://github.com/Bender97" target="_blank"><img src="data//icons8-github-white-color-96.png" width="16%" alt=""></a>
        &nbsp;&nbsp;
        <a href="https://scholar.google.com/citations?user=BF-qCIIAAAAJ&hl=it" target="_blank"><img src="data//icons8-google-scholar-white-color-96.png" width="16%" alt=""></a>
        &nbsp;&nbsp;<br><br>
        <a href="https://twitter.com/Bender97" target="_blank"><img src="data//icons8-twitter-circled-white-color-96.png" width="16%" alt=""></a>
        &nbsp;&nbsp;
        <a href="https://www.linkedin.com/in/daniel-fusaro-473320164/" target="_blank"><img src="data//icons8-linkedin-white-color-96.png" width="16%" alt=""></a>
        &nbsp;&nbsp;
      </p>
  </header>

      

<section class="outer" style="margin-left: 100px;">

<!-- About Me -->
<section id="about">
    <h3></h3>
    <p>
      I am a Ph.D. candidate in the <a href="https://www.dei.unipd.it/" target="_blank">Department of Information Engineering</a> at the <a href="https://www.unipd.it/" target="_blank">University of Padua</a>, advised by <a href="https://www.dei.unipd.it/~albertopretto/" target="_blank">Prof. Alberto Pretto</a> and <a href="https://www.dei.unipd.it/~emg/" target="_blank">Prof. Emanuele Menegatti</a>.
      I also collaborate closely with <a href="https://www.dei.unipd.it/persona/F77BA55F0AFDD50E2BB7D2388742999F" target="_blank">Prof. Loris Nanni</a>.
    </p>
    <p>
      <b>My research focuses include spatial intelligence, multimodal large language models, and 3D/4D world modeling and evaluations.</b>
    </p>
    <!--
    <p>
      I am the recipient of the
      <a href="https://credentials.nus.edu.sg/93ead292-7ca7-4913-a20d-3a9e6595e974" target="_blank">Research Achievement Award</a> (NUS Computing, 2023),
      <a href="https://credentials.nus.edu.sg/8a8727eb-17af-4489-8092-ac2b9cc83b01" target="_blank">Dean's Graduate Research Excellence Award</a> (NUS Computing, 2024),
      <a href="https://www.daad.de/en/the-daad/postdocnet/fellows/fellows/#KongLingdong" target="_blank">DAAD AInet Fellowship</a> (DAAD, 2025),
      and <a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2025" target="_blank">Apple Scholars in AI/ML Ph.D. Fellowship</a> (Apple, 2025).
    </p>
    <p>
      I have been fortunate to collaborate with <a href="https://machinelearning.apple.com/" target="_blank">Apple Machine Learning Research</a>, <a href="https://www.nvidia.com/en-us/research/" target="_blank">NVIDIA Research</a>,  <a href="https://www.bytedance.com/en/" target="_blank">ByteDance AI Lab</a>, <a href="https://openmmlab.com/" target="_blank">OpenMMLab</a>, <a href="https://www.mmlab-ntu.com/" target="_blank">MMLab@NTU</a>, and <a href="https://motional.com/" target="_blank">Motional</a>.
    </p>
    -->
    <!-- <p>
      </br>
      &#129409; I am open to discussion and collaboration in 3D perception, generation, and understanding. If you find our research backgrounds a potential match, feel free to email me.
    </p> -->
</section>



<!-- News -->
<section id="news">
  <h2>News</h2>
  <ul>
    <li>
      [09/2025] - Finalist Best Paper Award at the <a href="https://ecmr2025.dei.unipd.it/" target="_blank">12th European Conference on Mobile Robots (ECMR)</a> for the paper "ConUDA: Confidence-Guided Pseudo-Label Sampling for Unsupervised Domain Adaptation in 3D
      LiDAR Semantic Segmentation".
    </li>
    <li>
      [06/2025] - Honorable Mention at the <a href="https://usm3d.github.io/" target="_blank">2nd Building3D Challenge</a> of the 2nd Workshop on Urban Scene Modeling: Where Vision meets Photogrammetry and Graphics (USM3D), IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR workshops).
    </li>
    <li>
      [07/2022] - 8th place at the National Finals of the <a href="https://cyberchallenge.it/" target="_blank">CyberChallenge</a>.
    </li>
    <li>
      [01/2014] - European Finalist<a href="https://zerorobotics.mit.edu/" target="_blank">ZeroRobotics Competition</a>.
    </li>
  </ul>
</section>
        


<!-- Work -->
<section id="work">
  <h2>Industrial Experience</h2>
</section>

<section class="pub" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="40%" valign="center">
          &nbsp;&nbsp;&nbsp;<a class="image"><img src="logo/flexsight.png" width="70%" alt=""></a>
        </td>
        <td width="60%" align="center">
          <div class="title"><h4>FlexSight</h4></div>
          <div class="authors"><span class="author">Internship</span></div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td>
      </tr></tbody>
  </table>
</section>

      


      
<section id="research">
<h2>
Recent Publications
</h2>
<p><i>* equal contributions&nbsp;&nbsp;&nbsp;&nbsp;  ‡ project lead&nbsp;&nbsp;&nbsp;&nbsp;  § corresponding author</i></p>

<!-- Buttons for categories -->
<div class="categories">
  <button class="category-btn" onclick="filterPublications(&#39;all&#39;)" data-type="all">All</button>
  <button class="category-btn active" onclick="filterPublications(&#39;Selected&#39;)" data-type="Selected">Selected</button>
  <button class="category-btn" onclick="filterPublications(&#39;Perception&#39;)" data-type="Perception">Perception</button>
  <button class="category-btn" onclick="filterPublications(&#39;Generation&#39;)" data-type="Generation">Generation</button>
  <button class="category-btn" onclick="filterPublications(&#39;Understanding&#39;)" data-type="Understanding">Understanding</button>
  <button class="category-btn" onclick="filterPublications(&#39;Robustness&#39;)" data-type="Robustness">Robustness</button>
  <button class="category-btn" onclick="filterPublications(&#39;VLM&#39;)" data-type="VLM">LLM &amp; VLM</button>
</div>



<section class="pub publication-item" data-type="Selected, Generation, Understanding" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//worldlens.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World</p>
          </div>
          <div class="authors">
            <span class="author">Ao Liang</span>*,
            <span class="me">Daniel Fusaro</span>*<sup>,‡</sup>,
            <span class="author">Tianyi Yan</span>*,
            <span class="author">Hongsi Liu</span>*,
            <span class="author">Wesley Yang</span>*,
            <span class="author">Ziqi Huang</span>,
            <span class="author">Wei Yin</span>,
            <span class="author">Jialong Zuo</span>,
            <span class="author">Yixuan Hu</span>,
            <span class="author">Dekai Zhu</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2026
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://worldbench.github.io/worldlens" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/worldbench/WorldLens" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Data</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>



<section class="pub publication-item" data-type="Selected, Generation, Understanding" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//worldbench_survey.webp" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>3D and 4D World Modeling: A Survey</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>*,
            <span class="author">Wesley Yang</span>*,
            <span class="author">Jianbiao Mei</span>*,
            <span class="author">Youquan Liu</span>*,
            <span class="author">Ao Liang</span>*,
            <span class="author">Dekai Zhu</span>*,
            <span class="author">Dongyue Lu</span>*,
            <span class="author">Wei Yin</span>*,
            <span class="author">Xiaotao Hu</span>,
            <span class="author">Mingkai Jia</span>,
            <span class="author">Junyuan Deng</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2026
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://worldbench.github.io/survey.pdf" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://worldbench.github.io/survey" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/worldbench/survey" target="_blank">Code</a></span>
            <!-- &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="">Data</a></span> -->
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://mp.weixin.qq.com/s/yZdFa-jz3kSMHJWiFSjlIg" target="_blank">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Generation" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//lidarcrafter.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences</p>
          </div>
          <div class="authors">
            <span class="author">Ao Liang</span>,
            <span class="author">Youquan Liu</span>,
            <span class="author">Yu Yang</span>,
            <span class="author">Dongyue Lu</span>,
            <span class="author">Linfeng Li</span>,
            <span class="me">Daniel Fusaro</span><sup>‡</sup>,
            <!-- <span class="author">Huaici Zhao</span>,
            <span class="author">Wei Tsang Ooi</span> -->
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <a href="https://aaai.org/conference/aaai/aaai-26/" target="_blank">AAAI Conference on Artificial Intelligence (AAAI)</a>, 2026
            <!-- <i>Preprint</i>, 2025 -->
          </div>
          
            <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Oral Presentation</span>
          <div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2508.03692" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://lidarcrafter.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/lidarcrafter/toolkit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccvw25_lidarcrafter.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </div></td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Generation" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//la-la-lidar.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>La La LiDAR: Large-Scale Layout Generation from LiDAR Data</p>
          </div>
          <div class="authors">
            <span class="author">Youquan Liu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Weidong Yang</span>,
            <span class="author">Xin Li</span>,
            <span class="author">Ao Liang</span>,
            <span class="author">Runnan Chen</span>,
            <span class="author">Ben Fei</span>,
            <span class="author">Tongliang Liu</span>
          </div>
          <div class="venue">
            <a href="https://aaai.org/conference/aaai/aaai-26/" target="_blank">AAAI Conference on Artificial Intelligence (AAAI)</a>, 2026
            <!-- <i>Preprint</i>, 2025 -->
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2508.03691" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding, VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//vla4ad_survey.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Open-o3 Video: Grounded Video Reasoning with Spatio-Temporal Evidence</p>
          </div>
          <div class="authors">
            <span class="author">Jiahao Meng</span>,
            <span class="author">Xiangtai Li</span>,
            <span class="author">Haochen Wang</span>,
            <span class="author">Yue Tan</span>,
            <span class="author">Tao Zhang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Yunhai Tong</span>,
            <span class="author">Anran Wang</span>,
            <span class="author">Zhiyang Teng</span>,
            <span class="author">Yujing Wang</span>,
            <span class="author">Zhuochen Wang</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2510.20579" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://marinero4972.github.io/projects/Open-o3-Video/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/marinero4972/Open-o3-Video" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/marinero4972/Open-o3-Video/tree/main" target="_blank">Data</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding, VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//rewardmap.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>RewardMap: Tackling Sparse Rewards in Fine-Grained Visual Reasoning via Multi-Stage Reinforcement Learning</p>
          </div>
          <div class="authors">
            <span class="author">Sicheng Feng</span>*,
            <span class="author">Kaiwen Tuo</span>*,
            <span class="author">Song Wang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Jianke Zhu</span>,
            <span class="author">Huan Wang</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2510.02240" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://fscdc.github.io/RewardMap/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/fscdc/RewardMap" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/collections/FSCCS/reasonmap-688517b57d771707a5d64656" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://mp.weixin.qq.com/s/sPJLQtHgl5DZghWLWa_H3Q" target="_blank">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Generation, VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//editmgt.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing</p>
          </div>
          <div class="authors">
            <span class="author">Wei Chow</span>,
            <span class="author">Linfeng Li</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Zefeng Li</span>,
            <span class="author">Qi Xu</span>,
            <span class="author">Hang Song</span>,
            <span class="author">Tian Ye</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2506.03144" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://merit-2025.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/weichow23/merit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/WeiChow/merit" target="_blank">Data</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<!-- <section class="pub publication-item" data-type="Understanding">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="./images/paper/vla4ad_survey.png" width="88%" alt=""/></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>A Survey on 3D Scene Understanding in the Wild</p>
          </div>
          <div class="authors">
            <span class="author">Xiang Xu</span>*,
            <span class="author">Youquan Liu</span>*,
            <span class="author">Song Wang</span>,
            <span class="author">Ao Liang</span>,
            <span class="author">Wesley Yang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Qingshan Liu</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;" />
        </td></tr></tbody></table>
</section> -->


<!-- <section class="pub publication-item" data-type="Understanding">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="./images/paper/vla4ad_survey.png" width="88%" alt=""/></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Foundation Models for Multi-Modal Representation Learning from Onboard Sensors: A Survey</p>
          </div>
          <div class="authors">
            <span class="author">Song Wang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Xiaolu Liu</span>,
            <span class="author">Hao Shi</span>,
            <span class="author">Wentong Li</span>,
            <span class="author">Jianke Zhu</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;" />
        </td></tr></tbody></table>
</section> -->


<!-- <section class="pub publication-item" data-type="Generation">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="./images/paper/veila.png" width="88%" alt=""/></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Veila: Scaling Diffusion Models for Panoramic LiDAR Point Cloud Generation from a Single Image</p>
          </div>
          <div class="authors">
            <span class="author">Youquan Liu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Weidong Yang</span>,
            <span class="author">Ao Liang</span>,
            <span class="author">Jianxiong Gao</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2508.03690" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;" />
        </td></tr></tbody></table>
</section> -->


<section class="pub publication-item" data-type="Understanding, VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//reasonmap.jpg" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps</p>
          </div>
          <div class="authors">
            <span class="author">Sicheng Feng</span>*,
            <span class="author">Song Wang</span>*,
            <span class="author">Shuyi Ouyang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2505.18675" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://fscdc.github.io/Reason-Map/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/fscdc/ReasonMap" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/FSCCS/ReasonMap" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://mp.weixin.qq.com/s/sPJLQtHgl5DZghWLWa_H3Q" target="_blank">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception, Understanding, VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//ascent.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Stairway to Success: Zero-Shot Floor-Aware Object-Goal Navigation via LLM-Driven Coarse-to-Fine Exploration</p>
          </div>
          <div class="authors">
            <span class="author">Zeying Gong</span>,
            <span class="author">Rong Li</span>,
            <span class="author">Tianshuai Hu</span>,
            <span class="author">Ronghe Qiu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2505.23019" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zeying-gong.github.io/projects/ascent/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Zeying-Gong/ascent" target="_blank">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//pixelthink.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>PixelThink: Towards Efficient Chain-of-Pixel Reasoning</p>
          </div>
          <div class="authors">
            <span class="author">Song Wang</span>,
            <span class="author">Gongfan Fang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Xiangtai Li</span>,
            <span class="author">Jianyun Xu</span>,
            <span class="author">Sheng Yang</span>,
            <span class="author">Qiang Li</span>,
            <span class="author">Jianke Zhu</span>,
            <span class="author">Xinchao Wang</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2505.23727" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://pixelthink.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/songw-zju/PixelThink" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Data</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Generation" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//see4d.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>See4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting</p>
          </div>
          <div class="authors">
            <span class="author">Dongyue Lu</span>*,
            <span class="author">Ao Liang</span>*,
            <span class="author">Tianxin Huang</span>,
            <span class="author">Xiao Fu</span>,
            <span class="author">Yuyang Zhao</span>,
            <span class="author">LinFeng Li</span>,
            <span class="author">Songhua Liu</span>,
            <span class="author">Baorui Ma</span>,
            <span class="author">Liang Pan</span>,
            <span class="me">Daniel Fusaro</span><sup>‡</sup>,
            <span class="author">Ziwei Liu</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2510.26796" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://see-4d.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<!-- <section class="pub publication-item" data-type="Perception, Understanding">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="./images/paper/driving-peft.png" width="88%" alt=""/></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Parameter-Efficient Fine-Tuning for Vision-Centric Autonomous Driving</p>
          </div>
          <div class="authors">
            <span class="author">Song Wang</span>,
            <span class="author">Chunyong Hu</span>,
            <span class="author">Jianyun Xu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Wentong Li</span>,
            <span class="author">Sheng Yang</span>,
            <span class="author">Qiang Li</span>,
            <span class="author">Jianke Zhu</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;" />
        </td></tr></tbody></table>
</section> -->


<!-- <section class="pub publication-item" data-type="Selected, Perception, Understanding, VLM">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="./images/paper/talk2event.png" width="88%" alt=""/></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Event Camera Visual Grounding from Any Condition</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>*,
            <span class="author">Dongyue Lu</span>*,
            <span class="author">Ao Liang</span>*,
            <span class="author">Rong Li</span>,
            <span class="author">Yuhao Dong</span>,
            <span class="author">Tianshuai Hu</span>,
            <span class="author">Lai Xing Ng</span>,
            <span class="author">Wei Tsang Ooi</span>,
            <span class="author">Benoit R. Cottereau</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2507.17664" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://talk2event.github.io" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/talk2event/toolkit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="">Data</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;" />
        </td></tr></tbody></table>
</section> -->


<section class="pub publication-item" data-type="Selected, Perception, Understanding, VLM" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//talk2event.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>*,
            <span class="author">Dongyue Lu</span>*,
            <span class="author">Ao Liang</span>*,
            <span class="author">Rong Li</span>,
            <span class="author">Yuhao Dong</span>,
            <span class="author">et al.</span>
            <!-- <span class="author">Tianshuai Hu</span>,
            <span class="author">Lai Xing Ng</span>,
            <span class="author">Wei Tsang Ooi</span>,
            <span class="author">Benoit R. Cottereau</span> -->
          </div>
          <div class="venue">
            <a href="https://neurips.cc/Conferences/2025" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2025
          </div>
          
            <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Spotlight (3.2% = 688/21575)</span>
          <div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2507.17664" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://talk2event.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/talk2event/toolkit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccvw25_talk2event.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </div></td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Understanding, VLM" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//videolucy.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>VideoLucy: Deep Memory Backtracking for Long Video Understanding</p>
          </div>
          <div class="authors">
            <span class="author">Jialong Zuo</span>,
            <span class="author">Yongtai Deng</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Jingkang Yang</span>,
            <span class="author">Rui Jin</span>,
            <span class="author">Yiwei Zhang</span>,
            <span class="author">Nong Sang</span>,
            <span class="author">Liang Pan</span>,
            <span class="author">Ziwei Liu</span>,
            <span class="author">Changxin Gao</span>
          </div>
          <div class="venue">
            <a href="https://neurips.cc/Conferences/2025" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2510.12422" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://videolucy.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Zplusdragon/VideoLucy" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/jlongzuo/EgoMem" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips25_videolucy.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception, Understanding, VLM" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//3eed.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>3EED: Ground Everything Everywhere in 3D</p>
          </div>
          <div class="authors">
            <span class="author">Rong Li</span>*,
            <span class="author">Yuhao Dong</span>*,
            <span class="author">Tianshuai Hu</span>*,
            <span class="author">Ao Liang</span>*,
            <span class="author">Youquan Liu</span>*,
            <span class="author">Dongyue Lu</span>*,
            <span class="author">Liang Pan</span>,
            <span class="me">Daniel Fusaro</span><sup>‡</sup>,
            <span class="author">Junwei Liang</span>,
            <span class="author">Ziwei Liu</span>
          </div>
          <div class="venue">
            <a href="https://neurips.cc/Conferences/2025" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2511.01755" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://project-3eed.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/worldbench/3EED" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/RRRong/3EED" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips25_3eed.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="VLM" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//merit.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query</p>
          </div>
          <div class="authors">
            <span class="author">Wei Chow</span>,
            <span class="author">Yuan Gao</span>,
            <span class="author">Linfeng Li</span>,
            <span class="author">Xian Wang</span>,
            <span class="author">Qi Xu</span>,
            <span class="author">Hang Song</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Ran Zhou</span>,
            <span class="author">Yi Zeng</span>,
            <span class="author">Yidong Cai</span>,
            <span class="author">Botian Jiang</span>,
            <span class="author">Shilin Xu</span>,
            <span class="author">Jiajun Zhang</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <a href="https://neurips.cc/Conferences/2025" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2506.03144" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://merit-2025.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/weichow23/merit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/WeiChow/merit" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips25_merit.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Generation" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//spiral.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation and Understanding</p>
          </div>
          <div class="authors">
            <span class="author">Dekai Zhu</span>*,
            <span class="author">Yixuan Hu</span>*,
            <span class="author">Youquan Liu</span>,
            <span class="author">Dongyue Lu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Slobodan Ilic</span>
          </div>
          <div class="venue">
            <a href="https://neurips.cc/Conferences/2025" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2505.22643" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://dekai21.github.io/SPIRAL/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/worldbench/SPIRAL" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips25_spiral.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//flexevent.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>FlexEvent: Towards Flexible Event-Frame Object Detection at Varying Operational Frequencies</p>
          </div>
          <div class="authors">
            <span class="author">Dongyue Lu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Gim Hee Lee</span>,
            <span class="author">Camille Simon Chane</span>,
            <span class="author">Wei Tsang Ooi</span>
          </div>
          <div class="venue">
            <a href="https://neurips.cc/Conferences/2025" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2412.06708" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://flexevent.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/DylanOrange/flexevent" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips25_flexevent.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<!-- <section class="pub publication-item" data-type="Generation, Understanding">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="./images/paper/.png" width="88%" alt=""/></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>All-in-One LiDARGen</p>
          </div>
          <div class="authors">
            <span class="author">Youquan Liu</span>,
            <span class="author">Dekai Zhu</span>,
            <span class="author">Ao Liang</span>,
            <span class="author">Linfeng Li</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <i>Preprint</i>, 2025
          </div>
          <div>
            <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;" />
        </td></tr></tbody></table>
</section> -->

  
<!-- <section class="pub publication-item" data-type="Understanding">
    <table width="100%" align="center" border="0">
      <tbody>
        <tr>
          <td width="28%" valign="top">
            <a class="image"><img src="./images/paper/superflow++.png" width="88%" alt=""/></a>
          </td>
          <td width="72%" align="center">
            <div class="title">
              <p>SuperFlow++: Enhanced Spatiotemporal Consistency for Cross-Modal Data Pretraining</p>
            </div>
            <div class="authors">
              <span class="author">Xiang Xu</span>*,
              <span class="me">Daniel Fusaro</span>*,
              <span class="author">Hui Shuai</span>,
              <span class="author">Wenwei Zhang</span>,
              <span class="author">Liang Pan</span>,
              <span class="author">et al.</span>
            </div>
            <div class="venue">
              arXiv, 2025
            </div>
            <div>
              <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2407.06190" target="_blank">PDF</a></span>
              &nbsp; | &nbsp;
              <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Xiangxu-0103/SuperFlow" target="_blank">Code</a></span>
              &nbsp; | &nbsp;
              <i><img src="images/icon/icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://xiangxu-0103.github.io/SuperFlow" target="_blank">Home</a></span>
            <hr style="margin-top:0.8em; margin-bottom:0em;" />
          </td></tr></tbody></table>
</section> -->


<section class="pub publication-item" data-type="Selected, Perception, Robustness" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//pi3det.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Perspective-Invariant 3D Object Detection</p>
          </div>
          <div class="authors">
            <span class="author">Ao Liang</span>*,
            <span class="me">Daniel Fusaro</span>*,
            <span class="author">Dongyue Lu</span>*,
            <span class="author">Youquan Liu</span>,
            <span class="author">Jian Fang</span>,
            <span class="author">Huaici Zhao</span>,
            <span class="author">Wei Tsang Ooi</span>
          </div>
          <div class="venue">
            <a href="https://iccv.thecvf.com/Conferences/2025" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2507.17665" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://pi3det.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/pi3det/toolkit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/Pi3DET/data" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv25_pi3det.pdf" target="_blank">Poster</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception, Understanding, Robustness, VLM" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//drivebench.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives</p>
          </div>
          <div class="authors">
            <span class="author">Shaoyuan Xie</span>,
            <span class="me">Daniel Fusaro</span><sup>‡</sup>,
            <span class="author">Yuhao Dong</span>,
            <span class="author">Chonghao Sima</span>,
            <span class="author">et al.</span>
            <!-- <span class="author">Wenwei Zhang</span>,
            <span class="author">Qi Alfred Chen</span>,
            <span class="author">Ziwei Liu</span> -->
          </div>
          <div class="venue">
            <a href="https://iccv.thecvf.com/Conferences/2025" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2501.04003" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://drive-bench.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/drive-bench/toolkit" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/drive-bench/arena" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv25_drivebench.pdf" target="_blank">Poster</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//lima.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Beyond One Shot, Beyond One Perspective: Cross-View and Long-Horizon Distillation for Better LiDAR Representations</p>
          </div>
          <div class="authors">
            <span class="author">Xiang Xu</span>,
            <span class="me">Daniel Fusaro</span><sup>‡</sup>,
            <span class="author">Song Wang</span>,
            <span class="author">Chuanwei Zhou</span>,
            <span class="author">Qingshan Liu</span>
          </div>
          <div class="venue">
            <a href="https://iccv.thecvf.com/Conferences/2025" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2507.05260" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://xiangxu-0103.github.io/LiMA" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Xiangxu-0103/LiMA" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv25_lima.pdf" target="_blank">Poster</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//monomrn.png" width="88%" alt=""></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>MonoMRN: Monocular Semantic Scene Completion via Masked Recurrent Networks</p>
          </div>
          <div class="authors">
            <span class="author">Xuzhi Wang</span>,
            <span class="author">Xinran Wu</span>,
            <span class="author">Song Wang</span>,
            <span class="me">Daniel Fusaro</span><sup>§</sup>,
            <span class="author">Ziping Zhao</span>
          </div>
          <div class="venue">
            <a href="https://iccv.thecvf.com/Conferences/2025" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2507.17661" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/alanWXZ/MonoMRN" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/alanWXZ/MonoMRN" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv25_monomrn.pdf" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Robustness" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//safemap.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>SafeMap: Robust HD Map Construction from Incomplete Observations</p>
          </div>
          <div class="authors">
            <span class="author">Xiaoshuai Hao</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Rong Yin</span>,
            <span class="author">Pengwei Wang</span>,
            <span class="author">Jing Zhang</span>,
            <span class="author">Yunfeng Diao</span>,
            <span class="author">Shu Zhao</span>
          </div>
          <div class="venue">
            <a href="https://icml.cc/Conferences/2025" target="_blank">International Conference on Machine Learning (ICML)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2507.00861" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/icml25_safemap.png" target="_blank">Poster</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//eventfly.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>EventFly: Event Camera Perception from Ground to the Sky</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Dongyue Lu</span>,
          <span class="author">Xiang Xu</span>,
          <span class="author">Lai Xing Ng</span>,
          <span class="author">Wei Tsang Ooi</span>,
          <span class="author">Benoit R. Cottereau</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2025" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2025
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2503.19916" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://event-fly.github.io/" target="_blank">Home</a></span>
          <!-- &nbsp; | &nbsp;
          <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="">Code</a></span> -->
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr25_eventfly.pdf" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//limoe.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>LiMoE: Mixture of LiDAR Data Representation Learners from Automotive Scenes</p>
        </div>
        <div class="authors">
          <span class="author">Xiang Xu</span>*,
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Hui Shuai</span>,
          <span class="author">Liang Pan</span>,
          <span class="author">Ziwei Liu</span>,
          <span class="author">Qingshan Liu</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2025" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2025
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2501.04004" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/LiMoE" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Xiangxu-0103/LiMoE" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr25_limoe.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/1888627256907236483" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Robustness" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//geal.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>GEAL: Generalizable 3D Object Affordance Learning with Cross-Modal Consistency</p>
        </div>
        <div class="authors">
          <span class="author">Dongyue Lu</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Tianxin Huang</span>,
          <span class="author">Gim Hee Lee</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2025" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2025
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2412.09511" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://dylanorange.github.io/projects/geal/" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/DylanOrange/geal" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://huggingface.co/datasets/dylanorange/geal" target="_blank">Data</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr25_geal.pdf" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception, Understanding, VLM" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//seeground.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding</p>
        </div>
        <div class="authors">
          <span class="author">Rong Li</span>,
          <span class="author">Shijie Li</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Xulei Yang</span>,
          <span class="author">Junwei Liang</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2025" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2025
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2412.04383" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://seeground.github.io/" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/iris0329/SeeGround" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr25_seeground.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/32342996023" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//pointlora.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning</p>
        </div>
        <div class="authors">
          <span class="author">Song Wang</span>,
          <span class="author">Xiaolu Liu</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Jianyun Xu</span>,
          <span class="author">Chunyong Hu</span>,
          <span class="author">et al.</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2025" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2025
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2504.16023" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://github.com/songw-zju/PointLoRA" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/songw-zju/PointLoRA" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr25_pointlora.png" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Generation" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//dynamiccity.webp" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes</p>
        </div>
        <div class="authors">
          <span class="author">Hengwei Bian</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Haozhe Xie</span>,
          <span class="author">Liang Pan</span>,
          <span class="author">Yu Qiao</span>,
          <span class="author">Ziwei Liu</span>
        </div>
        <div class="venue">
          <a href="https://iclr.cc/Conferences/2025" target="_blank">International Conference on Learning Representations (ICLR)</a>, 2025
        </div>
          <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Spotlight (5.1% = 580/11372)</span>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2410.18084" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://dynamic-city.github.io/" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/3DTopia/DynamicCity" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iclr25_dynamiccity.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Understanding, Robustness" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//calib3d.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Calib3D: Calibrating Model Preferences for Reliable 3D Scene Understanding</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>*,
            <span class="author">Xiang Xu</span>*,
            <span class="author">Jun Cen</span>,
            <span class="author">Wenwei Zhang</span>,
            <span class="author">Kai Chen</span>,
            <span class="author">Ziwei Liu</span>
          </div>
          <div class="venue">
            <a href="https://wacv2025.thecvf.com/" target="_blank">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</a>, 2025
          </div>
            <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Oral Presentation</span>
          <div>
          <!-- </div>
            <img src="./images/icon/favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Oral Presentation (8.2% = 202/2458)</span>
          <div> -->
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2403.17010" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/Calib3D" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Bender97/Calib3D" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/wacv25_calib3d.pdf" target="_blank">Poster</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
       </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Understanding" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//large-ad.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>LargeAD: Large-Scale Cross-Sensor Data Pretraining for Autonomous Driving</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>*,
            <span class="author">Xiang Xu</span>*,
            <span class="author">Youquan Liu</span>*,
            <span class="author">Jun Cen</span>,
            <span class="author">Runnan Chen</span>,
            <span class="author">Wenwei Zhang</span>,
            <span class="author">Liang Pan</span>,
            <span class="author">Kai Chen</span>,
            <span class="author">Ziwei Liu</span>
          </div>
          <div class="venue">
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2501.04005" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/LargeAD" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Bender97/LargeAD" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/671066913" target="_blank">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Understanding" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//lasermix2.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Multi-Modal Data-Efficient 3D Scene Understanding for Autonomous Driving</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Xiang Xu</span>,
            <span class="author">Jiawei Ren</span>,
            <span class="author">Wenwei Zhang</span>,
            <span class="author">Liang Pan</span>,
            <span class="author">Kai Chen</span>,
            <span class="author">Wei Tsang Ooi</span>,
            <span class="author">Ziwei Liu</span>
          </div>
          <div class="venue">
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2405.05258" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/LaserMix++" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Bender97/LaserMix" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/528689803" target="_blank">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//frnet.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>FRNet: Frustum-Range Networks for Scalable LiDAR-Based Semantic Segmentation</p>
          </div>
          <div class="authors">
            <span class="author">Xiang Xu</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Hui Shuai</span>,
            <span class="author">Qingshan Liu</span>
          </div>
          <div class="venue">
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank">IEEE Transactions on Image Processing (TIP)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2312.04484" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://xiangxu-0103.github.io/FRNet" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Xiangxu-0103/FRNet" target="_blank">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//nuc-net.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>NUC-Net: Non-Uniform Cylindrical Partition Networks for Efficient LiDAR Semantic Segmentation</p>
          </div>
          <div class="authors">
            <span class="author">Xuzhi Wang</span>,
            <span class="author">Wei Feng</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Liang Wan</span>
          </div>
          <div class="venue">
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://ieeexplore.ieee.org/document/10938726" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/alanWXZ/NUC-Net" target="_blank">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception, Understanding" style="display: none;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//vfmseg.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Visual Foundation Models Boost Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation</p>
          </div>
          <div class="authors">
            <span class="author">Jingyi Xu</span>,
            <span class="author">Weidong Yang</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Youquan Liu</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6979" target="_blank">IEEE Transactions on Intelligent Transportation Systems (TITS)</a>, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2403.10001" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/EtronTech/VFMSeg" target="_blank">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<!-- <section class="pub">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="./images/paper/" width="88%" alt=""/></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Language-Driven Scene Understanding from Event Cameras</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Dongyue Lu</span>,
          <span class="author">Youquan Liu</span>,
          <span class="author">Lai Xing Ng</span>,
          <span class="author">Wei Tsang Ooi</span>,
          <span class="author">Benoit R. Cottereau</span>
        </div>
        <div class="venue">
          arXiv, 2025
        </div>
        <div>
          <i><img src="images/icon/icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="images/icon/icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Bender97/OpenESS" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="images/icon/icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/" target="_blank">Home</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0.26em;" />
      </td></tr></tbody></table>
</section> -->


<section class="pub publication-item" data-type="Selected, Understanding, Robustness" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//place3d.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Is Your LiDAR Placement Optimized for 3D Scene Understanding?</p>
        </div>
        <div class="authors">
          <span class="author">Ye Li</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Hanjiang Hu</span>,
          <span class="author">Xiaohao Xu</span>,
          <span class="author">Xiaonan Huang</span>
        </div>
        <div class="venue">
          <a href="https://neurips.cc/Conferences/2024" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2024
        </div>
          <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Spotlight (2.5% = 388/15671)</span>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2403.17009" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/ywyeli/Place3D" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips24_place3d.pdf" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception, Robustness" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//mapbench.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Is Your HD Map Constructor Reliable under Sensor Corruptions?</p>
        </div>
        <div class="authors">
          <span class="author">Xiaoshuai Hao</span>,
          <span class="author">Mengchuan Wei</span>,
          <span class="author">Yifan Yang</span>,
          <span class="author">Haimei Zhao</span>,
          <span class="author">Hui Zhang</span>,
          <span class="author">Yi Zhou</span>,
          <span class="author">Qiang Wang</span>,
          <span class="author">Weiming Li</span>,
          <span class="me">Daniel Fusaro</span><sup>§</sup>,
          <span class="author">Jing Zhang</span>
        </div>
        <div class="venue">
          <a href="https://neurips.cc/Conferences/2024" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2024
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2406.12214" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://mapbench.github.io/" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/mapbench/toolkit" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips24_mapbench.pdf" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//superflow.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>4D Contrastive Superflows are Dense 3D Representation Learners</p>
        </div>
        <div class="authors">
          <span class="author">Xiang Xu</span>*,
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Hui Shuai</span>,
          <span class="author">Wenwei Zhang</span>,
          <span class="author">Liang Pan</span>,
          <span class="author">Kai Chen</span>,
          <span class="author">Ziwei Liu</span>,
          <span class="author">Qingshan Liu</span>
        </div>
        <div class="venue">
          <a href="https://eccv.ecva.net/Conferences/2024" target="_blank">European Conference on Computer Vision (ECCV)</a>, 2024
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2407.06190" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://xiangxu-0103.github.io/SuperFlow" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Xiangxu-0103/SuperFlow" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/eccv24_superflow.jpg" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/1901989586143535730" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0.1em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//3d-uda.png" width="88%" alt=""></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Learning to Adapt SAM for Segmenting Cross-Domain Point Clouds</p>
        </div>
        <div class="authors">
          <span class="author">Xidong Peng</span>,
          <span class="author">Runnan Chen</span>,
          <span class="author">Feng Qiao</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Youquan Liu</span>,
          <span class="author">Tai Wang</span>,
          <span class="author">Xinge Zhu</span>,
          <span class="author">Yuexin Ma</span>
        </div>
        <div class="venue">
          <a href="https://eccv.ecva.net/Conferences/2024" target="_blank">European Conference on Computer Vision (ECCV)</a>, 2024
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2310.08820" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/eccv24_3d-uda.png" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Understanding" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//openess.png" width="88%" alt=""></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>OpenESS: Event-Based Semantic Scene Understanding with Open Vocabularies</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Youquan Liu</span>,
          <span class="author">Lai Xing Ng</span>,
          <span class="author">Benoit R. Cottereau</span>,
          <span class="author">Wei Tsang Ooi</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2024" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2024
        </div>
          <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Highlight (2.8% = 324/11532)</span>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2405.05259" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/OpenESS" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Bender97/OpenESS" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr24_open_ess.png" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//m3net.png" width="88%" alt=""></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Multi-Space Alignments Towards Universal LiDAR Segmentation</p>
        </div>
        <div class="authors">
          <span class="author">Youquan Liu</span>*,
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Xiaoyang Wu</span>,
          <span class="author">Runnan Chen</span>,
          <span class="author">Xin Li</span>,
          <span class="author">Liang Pan</span>,
          <span class="author">Ziwei Liu</span>,
          <span class="author">Yuexin Ma</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2024" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2024
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2405.01538" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/M3Net" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/youquanl/M3Net" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr24_m3net.png" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//4d-ds-net.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Unified 3D and 4D Panoptic Segmentation via Dynamic Shifting Networks</p>
        </div>
        <div class="authors">
          <span class="author">Fangzhou Hong</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Hui Zhou</span>,
          <span class="author">Xingge Zhu</span>,
          <span class="author">Hongsheng Li</span>,<br>
          <span class="author">Ziwei Liu</span>
        </div>
        <div class="venue">
          <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>, 2024
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://ieeexplore.ieee.org/document/10380457" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/hongfz16/DS-Net" target="_blank">Code</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception, Robustness" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//robobev.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>Benchmarking and Improving Bird's Eye View Perception Robustness in Autonomous Driving</p>
          </div>
          <div class="authors">
            <span class="author">Shaoyuan Xie</span>,
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Wenwei Zhang</span>,
            <span class="author">Jiawei Ren</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>, 2024
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2405.17426" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://daniel-xsy.github.io/robobev/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/Daniel-xsy/RoboBEV" target="_blank">Code</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-database-96.png" width="3.8%" alt="" loading="lazy"></i> <span class="tag"><a href="https://opendatalab.com/nuScenes-C" target="_blank">Data</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/" target="_blank">Zhihu</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
       </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Robustness" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//robodepth.png" width="88%" alt=""></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Shaoyuan Xie</span>,
          <span class="author">Hanjiang Hu</span>,
          <span class="author">Lai Xing Ng</span>,
          <span class="author">Benoit R. Cottereau</span>,
          <span class="author">Wei Tsang Ooi</span>
        </div>
        <div class="venue">
          <a href="https://neurips.cc/Conferences/2023" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2310.15171" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/RoboDepth" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/Bender97/RoboDepth" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-database-96.png" width="3.8%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Data</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips23_robodepth.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/673140450" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Understanding, VLM" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//seal.png" width="88%" alt=""></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Segment Any Point Cloud Sequences by Distilling Vision Foundation Models</p>
        </div>
        <div class="authors">
          <span class="author">Youquan Liu</span>*,
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Jun Cen</span>,
          <span class="author">Runnan Chen</span>,
          <span class="author">Wenwei Zhang</span>,
          <span class="author">et al.</span>
          <!-- <span class="author">Liang Pan</span>,
          <span class="author">Kai Chen</span>,
          <span class="author">Ziwei Liu</span> -->
        </div>
        <div class="venue">
          <a href="https://neurips.cc/Conferences/2023" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2023
        </div>
          <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;"> <span class="highlight">Spotlight (3.0% = 378/12343)</span>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt=""></i> <span class="tag"><a href="https://arxiv.org/abs/2306.09347" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/Seal" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt=""></i> <span class="tag"><a href="https://github.com/youquanl/Segment-Any-Point-Cloud" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-demo-96.png" width="3.9%" alt=""></i> <span class="tag"><a href="https://youtu.be/S0q2-nQdwSs" target="_blank">Demo</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt=""></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips23_seal.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt=""></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/671066913" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//transvae.jpg" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective</p>
        </div>
        <div class="authors">
          <span class="author">Pengfei Wei</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Xinghua Qu</span>,
          <span class="author">Yi Ren</span>,
          <span class="author">Zhiqiang Xu</span>,
          <span class="author">et al.</span>
          <!-- <span class="author">Jing Jiang</span>,
          <span class="author">Xiang Yin</span> -->
        </div>
        <div class="venue">
          <a href="https://neurips.cc/Conferences/2023" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2208.07365" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/TranSVAE" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/Bender97/TranSVAE" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-demo-96.png" width="3.9%" alt="" loading="lazy"></i> <span class="tag"><a href="https://huggingface.co/spaces/ldkong/TranSVAE" target="_blank">Demo</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips23_transvae.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/553169112" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//cns.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Towards Label-Free Scene Understanding by Vision Foundation Models</p>
        </div>
        <div class="authors">
          <span class="author">Runnan Chen</span>,
          <span class="author">Youquan Liu</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Nenglun Chen</span>,
          <span class="author">Xinge Zhu</span>,
          <span class="author">Yuexin Ma</span>,
          <span class="author">Tongliang Liu</span>,
          <span class="author">Wenping Wang</span>
        </div>
        <div class="venue">
          <a href="https://neurips.cc/Conferences/2023" target="_blank">Neural Information Processing Systems (NeurIPS)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2306.03899" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/runnanchen/Label-Free-Scene-Understanding" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/neurips23_cns.png" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception, Robustness" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//robo3d.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Robo3D: Towards Robust and Reliable 3D Perception against Corruptions</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Youquan Liu</span>*,
          <span class="author">Xin Li</span>*,
          <span class="author">Runnan Chen</span>,
          <span class="author">Wenwei Zhang</span>,
          <span class="author">Jiawei Ren</span>,
          <span class="author">Liang Pan</span>,
          <span class="author">Kai Chen</span>,
          <span class="author">Ziwei Liu</span>
        </div>
        <div class="venue">
          <a href="https://iccv2023.thecvf.com/" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2303.17597" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/Robo3D" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/Bender97/Robo3D" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-database-96.png" width="3.8%" alt="" loading="lazy"></i> <span class="tag"><a href="https://paperswithcode.com/paper/robo3d-towards-robust-and-reliable-3d" target="_blank">Data</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv23_robo3d.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/672935761" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//rangeformer.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Rethinking Range View Representation for LiDAR Segmentation</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Youquan Liu</span>,
          <span class="author">Runnan Chen</span>,
          <span class="author">Yuexin Ma</span>,
          <span class="author">Xinge Zhu</span>,
          <span class="author">Yikang Li</span>,
          <span class="author">Yuenan Hou</span>,
          <span class="author">Yu Qiao</span>,
          <span class="author">Ziwei Liu</span>
        </div>
        <div class="venue">
          <a href="https://iccv2023.thecvf.com/" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2303.05367" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv23_rethinking.pdf" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Perception" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//uniseg.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase</p>
        </div>
        <div class="authors">
          <span class="author">Youquan Liu</span>,
          <span class="author">Runnan Chen</span>,
          <span class="author">Xin Li</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Yuchen Yang</span>,
          <span class="author">et al.</span>
        </div>
        <div class="venue">
          <a href="https://iccv2023.thecvf.com/" target="_blank">IEEE/CVF International Conference on Computer Vision (ICCV)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2309.05573" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/PJLab-ADG/PCSeg" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/iccv23_uniseg.pdf" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception, Understanding" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//lasermix.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>LaserMix for Semi-Supervised LiDAR Semantic Segmentation</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Jiawei Ren</span>*,
          <span class="author">Liang Pan</span>,
          <span class="author">Ziwei Liu</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2023" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2023
        </div>
          <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;" loading="lazy"> <span class="highlight">Highlight (2.5% = 235/9155)</span>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2207.00026" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/LaserMix" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/Bender97/LaserMix" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-video-96.png" width="3.5%" alt="" loading="lazy"></i> <span class="tag"><a href="https://www.youtube.com/watch?v=7-zvIHKqkl0" target="_blank">Video</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr23_lasermix.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/528689803" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Understanding" style="display: none;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//clip2scene.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>CLIP2Scene: Towards Label-Efficient 3D Scene Understanding by CLIP</p>
        </div>
        <div class="authors">
          <span class="author">Runnan Chen</span>,
          <span class="author">Youquan Liu</span>,
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Xinge Zhu</span>,
          <span class="author">Yuexin Ma</span>,
          <span class="author">Yikang Li</span>,
          <span class="author">Yuenan Hou</span>,
          <span class="author">Yu Qiao</span>,
          <span class="author">Wenping Wang</span>
        </div>
        <div class="venue">
          <a href="https://cvpr.thecvf.com/Conferences/2023" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2301.04926" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/runnanchen/CLIP2Scene" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-video-96.png" width="3.5%" alt="" loading="lazy"></i> <span class="tag"><a href="https://www.youtube.com/watch?v=OT6AvAVlNNs" target="_blank">Video</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/cvpr23_clip2scene.png" target="_blank">Poster</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Perception" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//conda.jpeg" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Niamul Quader</span>,
          <span class="author">Venice Erin Liong</span>
        </div>
        <div class="venue">
          <a href="https://www.icra2023.org/" target="_blank">IEEE International Conference on Robotics and Automation (ICRA)</a>, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2111.15242" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/ConDA" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-tag-96.png" width="3.6%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/posters/icra23_conda.pdf" target="_blank">Poster</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-zhihu-192.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://zhuanlan.zhihu.com/p/531551329" target="_blank">Zhihu</a></span>
        </div>
        <hr style="margin-top:0.8em; margin-bottom:0em;">
      </td></tr></tbody></table>
</section>


<section class="pub publication-item" data-type="Selected, Robustness" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//robo3d_workshop.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>Benchmarking 3D Robustness to Common Corruptions and Sensor Failure</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>*,
          <span class="author">Youquan Liu</span>*,
          <span class="author">Xin Li</span>*,
          <span class="author">Runnan Chen</span>,
          <span class="author">Wenwei Zhang</span>,
          <span class="author">et al.</span>
          <!--
          <span class="author">Jiawei Ren</span>,
          <span class="author">Liang Pan</span>,
          <span class="author">Kai Chen</span>,
          <span class="author">Ziwei Liu</span> -->
        </div>
        <div class="venue">
          <a href="https://opendrivelab.com/sr4ad/iclr23" target="_blank">ICLR Workshop on Scene Representations for Autonomous Driving</a>, 2023
        </div>
          <img src="data//favorite.png" style="height: 20px; width: 20px; vertical-align: top;" loading="lazy"> <span class="highlight">Best Workshop Paper Award</span>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://openreview.net/pdf?id=pyi73rdeGP" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/Robo3D" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/Bender97/Robo3D" target="_blank">Code</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-database-96.png" width="3.8%" alt="" loading="lazy"></i> <span class="tag"><a href="https://paperswithcode.com/paper/robo3d-towards-robust-and-reliable-3d" target="_blank">Data</a></span>
        </div>
      </td></tr></tbody></table>
</section>

          

<section></section>



<section id="research">
<h2>Tech Reports</h2>
<br>

<section class="pub" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//robosense_challenge.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Shaoyuan Xie</span>,
            <span class="author">Zeying Gong</span>,
            <span class="author">Ye Li</span>,
            <span class="author">Meng Chu</span>,
            <span class="author">Ao Liang</span>,
            <!-- <span class="author">Zeying Gong</span>,
            <span class="author">Tianshuai Hu</span>,
            <span class="author">Ronghe Qiu</span>,
            <span class="author">Rong Li</span>,
            <span class="author">Meng Chu</span>,
            <span class="author">Hanjiang Hu</span>, -->
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            Technical Report, 2025
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://danielfusaro_placeholder.com/">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://robosense2025.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/robosense2025" target="_blank">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub" style="display: block;">
  <table width="100%" align="center" border="0">
    <tbody>
      <tr>
        <td width="28%" valign="top">
          <a class="image"><img src="data//robodrive_challenge.png" width="88%" alt="" loading="lazy"></a>
        </td>
        <td width="72%" align="center">
          <div class="title">
            <p>The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition</p>
          </div>
          <div class="authors">
            <span class="me">Daniel Fusaro</span>,
            <span class="author">Shaoyuan Xie</span>,
            <span class="author">Hanjiang Hu</span>,
            <span class="author">Yaru Niu</span>,
            <span class="author">Wei Tsang Ooi</span>,
            <span class="author">Benoit R. Cottereau</span>,
            <span class="author">Lai Xing Ng</span>,
            <span class="author">Yuexin Ma</span>,
            <span class="author">Wenwei Zhang</span>,
            <span class="author">Kai Chen</span>,
            <span class="author">et al.</span>
          </div>
          <div class="venue">
            Technical Report, 2024
          </div>
          <div>
            <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2405.08816" target="_blank">PDF</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://robodrive-24.github.io/" target="_blank">Home</a></span>
            &nbsp; | &nbsp;
            <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/robodrive-24/toolkit" target="_blank">Code</a></span>
          </div>
          <hr style="margin-top:0.8em; margin-bottom:0em;">
        </td></tr></tbody></table>
</section>


<section class="pub" style="display: block;">
<table width="100%" align="center" border="0">
  <tbody>
    <tr>
      <td width="28%" valign="top">
        <a class="image"><img src="data//robodepth_challenge.png" width="88%" alt="" loading="lazy"></a>
      </td>
      <td width="72%" align="center">
        <div class="title">
          <p>The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation</p>
        </div>
        <div class="authors">
          <span class="me">Daniel Fusaro</span>,
          <span class="author">Yaru Niu</span>,
          <span class="author">Shaoyuan Xie</span>,
          <span class="author">Hanjiang Hu</span>,
          <span class="author">Lai Xing Ng</span>,
          <span class="author">et al.</span>
          <!-- <span class="author">Benoit Cottereau</span>,
          <span class="author">Wei Tsang Ooi</span> -->
        </div>
        <div class="venue">
          Technical Report, 2023
        </div>
        <div>
          <i><img src="data//icons8-pdf-96.png" width="4%" alt="" loading="lazy"></i> <span class="tag"><a href="https://arxiv.org/abs/2307.15061" target="_blank">PDF</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-home-96.png" width="4.1%" alt="" loading="lazy"></i> <span class="tag"><a href="https://robodepth.github.io/" target="_blank">Home</a></span>
          &nbsp; | &nbsp;
          <i><img src="data//icons8-github-color-96.png" width="4.2%" alt="" loading="lazy"></i> <span class="tag"><a href="https://github.com/Bender97/RoboDepth" target="_blank">Code</a></span>
        </div>
      </td></tr></tbody></table>
</section>



<section></section>



<!-- Workshops -->
<section id="workshop">
  <h2>Workshop Organizers</h2>
  <ul>
    <li>
      <div class="title"><a href="https://www.iros25.org/" target="_blank">IROS 2025</a> - The RoboSense Challenge</div>
      <img src="data//icons8-home-96.png" width="3%" alt="" loading="lazy"> <a href="https://robosense2025.github.io/" target="_blank">Webpage</a>
      &nbsp; | &nbsp;
      <img src="data//icons8-location-96.png" width="2.8%" alt="" loading="lazy"> Venue: Hangzhou, China
    </li>
    <hr style="margin-top:1em; margin-bottom:1em;"> 
    <li>
      <div class="title"><a href="https://2024.ieee-icra.org/" target="_blank">ICRA 2024</a> - The RoboDrive Challenge</div>
      <img src="data//icons8-home-96.png" width="3%" alt="" loading="lazy"> <a href="https://robodrive-24.github.io/" target="_blank">Webpage</a>
      &nbsp; | &nbsp;
      <img src="data//icons8-location-96.png" width="2.8%" alt="" loading="lazy"> Venue: Yokohama, Japan
    </li>
    <hr style="margin-top:1em; margin-bottom:1em;"> 
    <li>
      <div class="title"><a href="https://www.icra2023.org/" target="_blank">ICRA 2023</a> - The RoboDepth Challenge</div>
      <img src="data//icons8-home-96.png" width="3%" alt="" loading="lazy"> <a href="https://robodepth.github.io/" target="_blank">Webpage</a>
      &nbsp; | &nbsp;
      <img src="data//icons8-location-96.png" width="2.8%" alt="" loading="lazy"> Venue: London, UK
    </li>
    <hr style="margin-top:1em; margin-bottom:1em;"> 
    <li>
      <div class="title"><a href="https://eccv2022.ecva.net/" target="_blank">ECCV 2022</a> - The PointCloud-C Challenge</div>
      <img src="data//icons8-home-96.png" width="3%" alt="" loading="lazy"> <a href="https://pointcloud-c.github.io/competition.html" target="_blank">Webpage</a>
      &nbsp; | &nbsp;
      <img src="data//icons8-location-96.png" width="2.8%" alt="" loading="lazy"> Venue: Virtual
    </li>
  </ul>
</section>



<!-- Academic Service -->
<section id="work">
  <h2>Academic Services</h2>
  <h3>Conference Reviewer</h3>
  <ul>
    <li>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<a href="https://cvpr.thecvf.com/" target="_blank">CVPR</a>)</li>
    <li>IEEE/CVF International Conference on Computer Vision (<a href="https://iccv.thecvf.com//" target="_blank">ICCV</a>)</li>
    <li>IEEE/CVF Winter Conference on Applications of Computer Vision (<a href="https://wacv.thecvf.com/" target="_blank">WACV</a>)</li>
    <li>European Conference on Computer Vision (<a href="https://eccv.ecva.net/" target="">ECCV</a>)</li>
    <li>Conference on Neural Information Processing Systems (<a href="https://neurips.cc/" target="_blank">NeurIPS</a>)</li>
    <li>International Conference on Learning Representations (<a href="https://iclr.cc/" target="_blank">ICLR</a>)</li>
    <li>International Conference on Machine Learning (<a href="https://icml.cc/" target="_blank">ICML</a>)</li>
    <li>IEEE International Conference on Robotics and Automation (<a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank">ICRA</a>)</li>
    <li>IEEE/RSJ International Conference on Intelligent Robots and Systems (<a href="https://www.ieee-ras.org/conferences-workshops/financially-co-sponsored/iros" target="_blank">IROS</a>)</li>
    <li>AAAI Conference on Artificial Intelligence (<a href="https://aaai.org/conference/aaai/" target="_blank">AAAI</a>)</li>
  </ul>
  <h3>Journal Reviewer</h3>
  <ul>
    <li>International Journal of Computer Vision (<a href="https://www.springer.com/journal/11263" target="_blank">IJCV</a>)</li>
    <li>International Journal of Robotics Research (<a href="https://journals.sagepub.com/home/ijr" target="_blank">IJRR</a>)</li>
    <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI</a>)</li>
    <li>IEEE Transactions on Neural Networks and Learning Systems (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385" target="_blank">TNNLS</a>)</li>
    <li>IEEE Transactions on Intelligent Vehicles (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274857" target="_blank">TIV</a>)</li>
    <li>IEEE Transactions on Intelligent Transportation Systems (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6979" target="_blank">TITS</a>)</li>
    <li>IEEE Transactions on Circuits and Systems for Video Technology (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank">TCSVT</a>)</li>
    <li>IEEE Transactions on Multimedia (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046" target="_blank">TMM</a>)</li>
    <li>IEEE Transactions on Knowledge and Data Engineering (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69" target="_blank">TKDE</a>)</li>
    <li>IEEE Robotics and Automation Letters (<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369" target="_blank">RA-L</a>)</li>
    <li>ISPRS Journal of Photogrammetry and Remote Sensing (<a href="https://www.sciencedirect.com/journal/isprs-journal-of-photogrammetry-and-remote-sensing" target="_blank">P&amp;RS</a>)</li>
  </ul>
  <!-- <h3>Teaching Assistant</h3>
  <ul>
    <li>CS3263 - Foundations of Artificial Intelligence, AY23/24, Sem 2</li>
    <li>CS4243 - Computer Vision and Pattern Recognition, AY23/24, Sem 1</li>
  </ul> -->
</section>
</section>
    


<!-- Footer -->
<section id="footer">
  <div class="container">
    <ul class="copyright">
      <li>© Last Updated: November 2025</li>
    </ul>
  </div>
</section>

<section id="footer">
  <div class="container">
    <ul class="copyright"><li></li></ul>
  </div>
</section>

        
</section>
</section></div>






<script>
  document.addEventListener('DOMContentLoaded', function () {
    const newsList = document.getElementById('news-list');
    const scrollIndicator = document.getElementById('scroll-indicator');
    const newsItems = newsList.getElementsByTagName('li');
    let visibleItems = 5;

    function showItems(startIndex, endIndex) {
      for (let i = startIndex; i < endIndex && i < newsItems.length; i++) {
        setTimeout(() => {
          newsItems[i].classList.add('visible');
        }, (i - startIndex) * 100);
      }
    }

    function hideExtraItems() {
      for (let i = visibleItems; i < newsItems.length; i++) {
        newsItems[i].style.display = 'none';
      }
    }

    function showMoreItems() {
      const nextEndIndex = Math.min(visibleItems + 3, newsItems.length);
      for (let i = visibleItems; i < nextEndIndex; i++) {
        newsItems[i].style.display = '';
      }
      showItems(visibleItems, nextEndIndex);
      visibleItems = nextEndIndex;

      if (visibleItems >= newsItems.length) {
        scrollIndicator.style.display = 'none';
      }
    }

    hideExtraItems();
    showItems(0, visibleItems);

    if (newsItems.length > visibleItems) {
      scrollIndicator.style.display = 'block';
    }

    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting && visibleItems < newsItems.length) {
          showMoreItems();
        }
      });
    }, { threshold: 1.0 });

    observer.observe(scrollIndicator);
  });
</script>




<script>
  let isOriginal = true;

  function switchImage() {
      const img = document.getElementById('avatar-image');
      if (isOriginal) {
          img.src = 'data/mypics/photo_me.jpeg'; // Set to the new image
      } else {
          img.src = 'data/mypics/photo_me.jpeg'; // Set back to the original image
      }
      isOriginal = !isOriginal; // Toggle the state
  }
</script>


</body></html>